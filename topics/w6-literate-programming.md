# Literate Programming

### The struggle with documentation

The documentation of code is essential for people to be able to maintain and reuse code. One common case where good documentation is often sorely missed is when downloading the code from a research paper and trying to understand how it works. The code can significantly diverge from the way it is presented in the paper as there are a lot of technical details glossed over in the paper and the nicest mathematical representation may not be the best computational implementation. In these cases thorough documentation describing how to code lines up with the paper and why for example a value is calculated the way it is, would be greatly appreciated. 
The reality, however, is that documentation is often treated as an after thought. In the rush to get papers published thorough documentation is often neglected in favour of polishing other parts (namely the ones that reviewers are more likely to look at). But, perhaps if we imagine a world where all code is properly documented, the time saved in deciphering other people's code could be enough to also provide proper documentation of one's own code. This is the world envisioned by **literate programming**; A world in which proper documentation is part and parcel of what it means to write a programm.  

### WEB - Where it all began
In 1984 Donald Knuth published WEB the first literate programming language [1]. The guiding philosophy behind literate programming is that one could achieve far superior documentation of code by considering programms as works of literature. Knuth writes: "Instead of imagining that our main task is to instruct a *computer* what to do, let us concentrate rather on explaining to *human beings* what we want a computer to do.". Accordingly, WEB is made to allow authors of programms to narrate their code, interweaving programming language with prose that elucidates what a piece of code should achieve and why it is written the way it is. To achieve this WEB uses two subprocesses called TANGLE and WEAVE that act as intermediate compilers. TANGLE takes the WEB source file and compiles it to PASCAL from where a PASCAL compiler can then compile it to an executable. WEAVE on the other hand compiles WEB to TEX from where it can rendered to a human readable format. In essence TANGLE procudes the WEB programm the computer reads and WEAVE produces the programm that humans read. 
Importantly, the result of WEAVE is not simply a version of the pascal code with extensive comments. An essential part of WEB is the use of named code blocks. Named code block allows authors to write a block of code and refer to it by name to have that code inlined at that location similar to a macro. This lets authors boil down the purpose of a block to a simple description, greatly simplifying the areas of code that make use of the blocks.
For example a function that adds a string to a buffer may have more code dedicated to sanitizing the string then actually adding the string. Thus, an author may begin to worry that the function looks like it achieves a different purpose and cut back on the sanitization. But, by defining a code block "string sanitization" the buffer function will only contain that one line and the "string sanitization" code block can be written as elaborate as it needs to be. 
Another crucial component of WEB is its extensive hyperlink structure which the name WEB is based on. The output of WEAVE produces an index of all defined functions showing where they are defined and referenced, the references to named function block provide links and the prose can reference other relevant parts of the code and outside sources. This structure makes a WEB programm eminently more searchable than the equivalent PASCAL programm. 

### Computational Notebooks - The present state of literate programming?

In his original paper Knuth writes: "I made a conscious decision not to design a language that would be suitable for everybody. My goal was to provide a tool for system programmers, not for high school students or for hobbyists". He writes that the profusion of languages involved in WEB introduces a large variety of potential bugs and syntax errors, the complexity of which is more suitable for computer scientists than hobbyists to handle. Ironically, however, literate programming never really caught on in systems programming and instead it is most commonly argued that computational notebooks - a more beginner friendly, high-level programming interface - are the present form of literate programming [2]. It is easy to see the reasoning behind this. Computational notebooks allow users to easily interweave exposition blocks with code blocks. This, however, is a rather superficial comparison in certain key aspects. 
The main aspect wherein literate programming and notebooks diverge is that literate programms in the vein of WEB produce executable binaries of the same form as the equivalent illiterate programms. In particular, this means that authors do not need to worry about there programms being less performant simply for having written it in a literate fashion. In notebooks like Jupyter - the most popular notebook - the execution paradigm is completely different from the equivalent illiterate programm, often with much worse performance and significantly more crashes. Moreover, unlike Knuth's form of literate programming where the literate language should be a wrapper on top of the original language that is kept as simple as possible, notebooks provide a lot of extra functionality, like showing the programm output inside the notebook, code-block execution, out-of-order execution etc. When asking users why they use notebooks it appears that these other features, more so than the literate aspect of text blocks, are what contributes to the popularity of notebooks. In this vain one may argue that notebooks are less literate programms than they are a form of programming that also happens to integrate some of the ideas of literate programming. 
Continuing in this fashion one may also argue that all programms have become more literate. Modern IDEs provide a lot of the features that WEB brought to the table like pretty printing, and an extensive hyperlink structure that makes the code more searchable. But again, the underlying philosophy of literate programming is lost. 
Just as Knuth originally wrote: "... there are also a lot of computer scientists who will not enjoy using WEB; some of us are glad that traditional programming languages have comparatively primitive capabilities for inserted comments, because such difficulties provide a good excuse for not documenting programs well" it would appear that the documentation presents to arduous a task for many programmers to do it freely.

### AI - The future of documentation 

With the introduction of large language models (LLMs) into the programming workflow the process of IDEs taking on all the features of literate programming may come full circle. GitHub CoPilot already allows users to easily generate docstrings for their functions only requiring small corrections here and there. Similarly, as code is increasingly written by LLMs, the prompt used to generate the code could be added inside the code as a sort of literate documentation, an idea already introduced by Colaroid [5]. 
However, the final aspect of literate programming that motivated Knuth's publication can never be captured by LLM generation. This is the aspect that writing programms in a literate fashion can make programmers better at their work, as it makes the author think more carefully about the code. 

Ultimately, it all comes down to the point that literate programming is not a tool or an interface, but rather a philosophy on how to approach writing code. Thus, while a tool may ease users into adopting this philosophy, no tool will be a literate programming tool nor will any interface be a literate programming interface. Instead there will be programmers who write literate programms and those who do not.

### Bibliography
[1] Knuth, Donald Ervin. "Literate programming." The computer journal 27, no. 2 (1984): 97-111.

[2] Lau, S., Drosos, I., Markel, J. M., & Guo, P. J. (2020, August). The design space of computational notebooks: An analysis of 60 systems in academia and industry. In 2020 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC) (pp. 1-11). IEEE.

[5] April Yi Wang, Andrew Head, Ashley Ge Zhang, Steve Oney, and Christopher Brooks. 2023. Colaroid: A Literate Programming Approach for Authoring Explorable Multi-Stage Tutorials. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23). Association for Computing Machinery, New York, NY, USA, Article 798, 1â€“22. https://doi.org/10.1145/3544548.3581525
